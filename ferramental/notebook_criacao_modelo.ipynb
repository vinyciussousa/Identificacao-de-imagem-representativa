{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_treino = 'treino'\n",
    "dir_teste = 'teste'\n",
    "\n",
    "treino_demonstracoes = ['treino/{}'.format(i) for i in os.listdir(dir_treino) if 'positivo' in i]\n",
    "treino_ndemonstracoes = ['treino/{}'.format(i) for i in os.listdir(dir_treino) if 'negativo' in i]\n",
    "\n",
    "imgs_teste = ['teste/{}'.format(i) for i in os.listdir(dir_teste) if 'teste' in i]\n",
    "\n",
    "imgs_treino = treino_demonstracoes + treino_ndemonstracoes\n",
    "# une os datasets (se tiver quantidade suficiente repartir com [:xvalor])\n",
    "random.shuffle(imgs_treino)\n",
    "# embaralha as imagens\n",
    "\n",
    "del treino_demonstracoes\n",
    "del treino_ndemonstracoes\n",
    "gc.collect()\n",
    "# limpar o que n vai mais ser usado e coleta lixo para salvar memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlinhas = 150\n",
    "ncolunas = 150\n",
    "canais = 3\n",
    "# declaração das dimensões das imagens, 3 canais para RGB e 1 para Grayscale\n",
    "\n",
    "# função para ler e processar as imagens para um formato aceitavel para o modelo, retorna 2 arrays, um de imagens redimensionadas e um de rotulos\n",
    "def ler_e_processar_imagens(lista_de_imagens):\n",
    "    X = [] #imagens\n",
    "    y = [] #rotulos\n",
    "\n",
    "    for imagem in lista_de_imagens:\n",
    "        X.append(cv2.resize(cv2.imread(imagem, cv2.IMREAD_COLOR), (nlinhas, ncolunas), interpolation=cv2.INTER_CUBIC))\n",
    "        # coleta os rotulos\n",
    "        if 'positivo' in imagem:\n",
    "            y.append(1)\n",
    "        if 'negativo' in imagem:\n",
    "            y.append(0)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processa as imagens de treino e seus rotulos\n",
    "X, y = ler_e_processar_imagens(imgs_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "del imgs_treino\n",
    "gc.collect()\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "# conversão das listas para arrays numpy\n",
    "\n",
    "sns.countplot(y)\n",
    "plt.title('Rotulos')\n",
    "# plota os rotulos para conferirmos se esta correto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"O formato das imagens de treino é: \", X.shape)\n",
    "print(\"O formato dos rotulos é: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide o dataset em imagens de treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_treino, X_val, y_treino, y_val = train_test_split(X, y, test_size=0.20, random_state=2)\n",
    "\n",
    "print(\"Formato das imagens de treino é: \", X_treino.shape)\n",
    "print(\"Formato das imagens de validação: \", X_val.shape)\n",
    "print(\"Formato dos rotulos é: \", y_treino.shape)\n",
    "print(\"Formato dos rotulos é: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X\n",
    "del y\n",
    "gc.collect()\n",
    "# limpeza de memoria\n",
    "\n",
    "ntreino = len(X_treino)\n",
    "nval = len(X_val)\n",
    "# pega o tamanho dos dados de treino e validação\n",
    "\n",
    "batch_size = 32\n",
    "# inicialmente usar batch_size de 32, o batch_size deve ser fator de 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "\n",
    "conv_base = InceptionResNetV2(weights = 'imagenet', include_top = False, input_shape = (150,150,3))\n",
    "# chama o modelo pretreinado, com os pesos da imagenet e sem a camada do cima, para adicionar a que é precisa\n",
    "\n",
    "conv_base.summary()\n",
    "# sumario das camada de convolução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "modelo = models.Sequential()\n",
    "modelo.add(conv_base)\n",
    "modelo.add(layers.Flatten())\n",
    "modelo.add(layers.Dense(256, activation='relu'))\n",
    "modelo.add(layers.Dense(1, activation='sigmoid'))\n",
    "# importado camadas e modelos do keras e combinados a camada de convolução pegada anteriormente\n",
    "\n",
    "modelo.summary()\n",
    "# mostra o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Número de pesos treinaveis antes de congelar a conv_base: \", len(modelo.trainable_weights))\n",
    "conv_base.trainable = False\n",
    "print(\"Número de pesos treinaveis depois de congelar a conv_base: \", len(modelo.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "modelo.compile(loss = \"binary_crossentropy\", optimizer = optimizers.RMSprop(lr = 2e-5), metrics = [\"acc\"])\n",
    "# compila o modelo usando o otimizador RMS prop com um learning rate de 2e-5, e loss com binary_crossentropy já que é uma classificação binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# aumentação já que o dataset é pequeno\n",
    "datagen_treino = ImageDataGenerator(rescale=1./255,   \n",
    "                                    rotation_range=40,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    fill_mode='nearest')\n",
    "\n",
    "# dados de validação não precisam de aumentação, apenas de re-escala\n",
    "datagen_val = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerador_treino = datagen_treino.flow(X_treino, y_treino, batch_size = batch_size)\n",
    "gerador_val = datagen_val.flow(X_val, y_val, batch_size = batch_size)\n",
    "# criação dos geradores de imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historico = modelo.fit_generator(gerador_treino,\n",
    "                              steps_per_epoch = ntreino // batch_size,\n",
    "                              epochs = 64,\n",
    "                              validation_data = gerador_val,\n",
    "                              validation_steps = nval // batch_size)\n",
    "\n",
    "# treino com 64 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.save_weights(\"pesos_modelo_inceptionresnetv2_teste_150_64.h5\")\n",
    "modelo.save(\"modelo_inceptionresnetv2_teste_150_64.h5\")\n",
    "# salvamento dos pesos e do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pega os detalhes do historico\n",
    "acc = historico.history['acc']\n",
    "val_acc = historico.history['val_acc']\n",
    "loss = historico.history['loss']\n",
    "val_loss = historico.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# precisão de treino e validação\n",
    "plt.plot(epochs, acc, 'b', label='Precisão treino')\n",
    "plt.plot(epochs, val_acc, 'r', label='Precisão validação')\n",
    "plt.title('Precisão de treino e validação')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "# perda de treino e validação\n",
    "plt.plot(epochs, loss, 'b', label='Perda de treino')\n",
    "plt.plot(epochs, val_loss, 'r', label='Perda de validação')\n",
    "plt.title('Perda de treino e validação')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "# mostra os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suaviza(pontos, fator=0.7):\n",
    "    suaviza_pts = []\n",
    "    for ponto in pontos:\n",
    "        if suaviza_pts:\n",
    "            anterior = suaviza_pts[-1]\n",
    "            suaviza_pts.append(anterior * fator + ponto * (1 - fator))\n",
    "        else:\n",
    "            suaviza_pts.append(ponto)\n",
    "    return suaviza_pts\n",
    "\n",
    "# função para suavizar os graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, suaviza(acc), 'b', label='Precisão de treino')\n",
    "plt.plot(epochs, suaviza(val_acc), 'r', label='Precisão de validação')\n",
    "plt.title('Precisão de treino e validação')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# mostra os graficos suavizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste, y_teste = ler_e_processar_imagens(imgs_teste[0:10])\n",
    "x = np.array(X_teste)\n",
    "datagen_teste = ImageDataGenerator(rescale = 1./255)\n",
    "# tenta prever as 10 primeiras imagens do dataset de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "colunas = 5\n",
    "rotulos_texto = []\n",
    "plt.figure(figsize=(30,20))\n",
    "for batch in datagen_teste.flow(x, batch_size=1):\n",
    "    pred = modelo.predict(batch)\n",
    "    if pred > 0.5:\n",
    "        rotulos_texto.append('positivo')\n",
    "    else:\n",
    "        rotulos_texto.append('negativo')\n",
    "    plt.subplot(int(5 / colunas + 1), colunas, i + 1)\n",
    "    plt.title('Result ' + rotulos_texto[i])\n",
    "    imgplot = plt.imshow(batch[0])\n",
    "    i += 1\n",
    "    if i % 10 == 0:\n",
    "        break\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db8a8393f2943109b6fc78de225819a032cf6e6096f90570efc946334568982f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venvmodel': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
